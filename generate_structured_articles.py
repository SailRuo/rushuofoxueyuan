#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§£æHTMLæ–‡ç« ï¼Œç”Ÿæˆç»“æ„åŒ–JSONæ–‡ä»¶
ä¿ç•™æ ·å¼ä¿¡æ¯ï¼ˆé¢œè‰²ã€å­—ä½“ç­‰ï¼‰
"""

import os
import json
import re
from html.parser import HTMLParser
from pathlib import Path

class StructuredArticleParser(HTMLParser):
    """è§£æHTMLæ–‡ç« ï¼Œç”Ÿæˆç»“æ„åŒ–å†…å®¹"""
    
    def __init__(self):
        super().__init__()
        self.title = ""
        self.author = ""
        self.summary = ""
        self.sections = []
        self.content = []  # ç»“æ„åŒ–å†…å®¹
        
        self.current_tag = ""
        self.current_attrs = {}
        self.current_text = ""
        self.current_style = {}
        
        self.in_title = False
        self.in_section = False
        self.in_table = False
        self.in_content = True  # é»˜è®¤å¼€å§‹æ”¶é›†å†…å®¹
        self.skip_nav = False
        
    def handle_starttag(self, tag, attrs):
        self.current_tag = tag
        self.current_attrs = dict(attrs)
        
        # æå–æ ·å¼ä¿¡æ¯
        self.current_style = {
            'color': self.current_attrs.get('color', ''),
            'face': self.current_attrs.get('face', ''),
            'size': self.current_attrs.get('size', ''),
            'align': self.current_attrs.get('align', '')
        }
        
        # æ£€æµ‹æ ‡é¢˜ - H2æ ‡ç­¾
        if tag == 'h2':
            self.in_title = True
            self.current_text = ""
            
        # æ£€æµ‹ç« èŠ‚ - H4æ ‡ç­¾
        if tag == 'h4':
            self.in_section = True
            self.current_text = ""
            
        # æ£€æµ‹è¡¨æ ¼
        if tag == 'table':
            self.in_table = True
            self.content.append({
                'type': 'table',
                'rows': []
            })
            
        # æ£€æµ‹è¡¨æ ¼è¡Œ
        if tag == 'tr' and self.in_table:
            if self.content and self.content[-1]['type'] == 'table':
                self.content[-1]['rows'].append([])
                
        # æ£€æµ‹æ®µè½
        if tag == 'p':
            self.current_text = ""
            self.skip_nav = False
    
    def handle_endtag(self, tag):
        if tag == 'h2':
            self.in_title = False
            if self.current_text.strip() and not self.title:
                # æ¸…ç†æ ‡é¢˜
                title = self.current_text.strip()
                title = re.sub(r'-å¦‚è¯´ä¿®è¡Œ.*', '', title)
                title = re.sub(r'["\']', '', title)
                self.title = title
            self.current_text = ""
                
        if tag == 'h4':
            self.in_section = False
            if self.current_text.strip():
                # æ¸…ç†ç« èŠ‚æ ‡é¢˜ï¼ˆå»æ‰åºå·ï¼‰
                section_title = re.sub(r'^\d+[ã€.]', '', self.current_text).strip()
                section_title = re.sub(r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[ã€.]', '', section_title).strip()
                if section_title and len(section_title) > 1:
                    self.sections.append(section_title)
                    self.content.append({
                        'type': 'section',
                        'text': section_title
                    })
            self.current_text = ""
                
        if tag == 'table':
            self.in_table = False
            
        if tag == 'p':
            text = self.current_text.strip()
            if text and not self.skip_nav and len(text) > 1:
                # åˆ¤æ–­å†…å®¹ç±»å‹
                content_type = 'paragraph'
                
                # çº¢è‰²æˆ–æ·±çº¢è‰²æ¥·ä½“ = æ‘˜è¦/é‡è¦æç¤º
                color = self.current_style.get('color', '').upper()
                font = self.current_style.get('face', '')
                
                if (('CC3300' in color or 'FF0000' in color or 'DC2626' in color) and 
                    ('æ¥·ä½“' in font or 'KaiTi' in font)):
                    content_type = 'highlight'
                    if not self.summary and len(text) > 10:
                        self.summary = text[:200]
                
                self.content.append({
                    'type': content_type,
                    'text': text,
                    'style': {
                        'color': self.current_style.get('color', ''),
                        'font': self.current_style.get('face', ''),
                        'align': self.current_style.get('align', '')
                    }
                })
            
            self.current_text = ""
            self.skip_nav = False
    
    def handle_data(self, data):
        data = data.strip()
        if not data:
            return
        
        # è·³è¿‡å¯¼èˆªæ–‡æœ¬
        if any(nav in data for nav in ['å¦‚è¯´ä¿®è¡Œ', 'å‡€ä¿®é™¢', 'ç¦…ä¿®é™¢', 'ä¿®å­¦å›­åœ°', 'ç½‘ä¸Šä½›å­¦é™¢']):
            self.skip_nav = True
            return
        
        # è·³è¿‡ç©ºç™½å­—ç¬¦
        if data in ['ã€€', ' ', '\n', '\r', '\t']:
            return
            
        # æ”¶é›†æ–‡æœ¬
        if self.in_table:
            # è¡¨æ ¼å†…å®¹
            if self.content and self.content[-1]['type'] == 'table':
                if self.content[-1]['rows']:
                    self.content[-1]['rows'][-1].append(data)
        else:
            # æ™®é€šæ–‡æœ¬ - ç´¯ç§¯åˆ°current_text
            if self.current_text:
                self.current_text += data
            else:
                self.current_text = data

def parse_and_generate(file_path):
    """è§£æHTMLæ–‡ä»¶å¹¶ç”Ÿæˆç»“æ„åŒ–JSON"""
    try:
        # å°è¯•å¤šç§ç¼–ç 
        encodings = ['gb2312', 'gbk', 'utf-8', 'gb18030']
        content = None
        used_encoding = None
        
        for encoding in encodings:
            try:
                with open(file_path, 'r', encoding=encoding) as f:
                    content = f.read()
                used_encoding = encoding
                break
            except (UnicodeDecodeError, LookupError):
                continue
        
        if not content:
            print(f"  âš ï¸  æ— æ³•è§£ç æ–‡ä»¶")
            return None
        
        # è§£æ
        parser = StructuredArticleParser()
        parser.feed(content)
        
        # æ¸…ç†æ ‡é¢˜
        title = parser.title.strip()
        if not title:
            # å°è¯•ä»æ–‡ä»¶åæå–æ ‡é¢˜
            filename = file_path.name
            # å»æ‰æ‰©å±•åå’Œæ•°å­—å‰ç¼€
            title = re.sub(r'^\d+', '', filename.replace('.html', ''))
            if not title or len(title) < 2:
                return None
        
        # æ¸…ç†æ ‡é¢˜ä¸­çš„ç‰¹æ®Šå­—ç¬¦å’Œåç¼€
        title = re.sub(r'["\']', '', title)
        title = re.sub(r'-å¦‚è¯´ä¿®è¡Œ.*', '', title)
        title = re.sub(r'å¦‚è¯´ä¿®è¡Œ.*', '', title)
        title = title.strip()
        
        if not title or len(title) < 2:
            return None
        
        # å¦‚æœæ²¡æœ‰å†…å®¹ï¼Œè·³è¿‡
        if not parser.content or len(parser.content) == 0:
            print(f"  âš ï¸  æ— å†…å®¹")
            return None
        
        return {
            'title': title,
            'author': parser.author,
            'summary': parser.summary,
            'sections': parser.sections,
            'content': parser.content
        }
        
    except Exception as e:
        print(f"  âŒ è§£æå¤±è´¥: {e}")
        return None

def determine_category(filename):
    """æ ¹æ®æ–‡ä»¶ååˆ¤æ–­åˆ†ç±»"""
    if 'chan' in filename or 'ç¦…' in filename:
        return 'ç¦…ä¿®é™¢'
    elif 'jingtu' in filename or 'å‡€åœŸ' in filename:
        return 'å‡€ä¿®é™¢'
    else:
        return 'ä¿®å­¦å›­åœ°'

def extract_tags(title, summary, sections):
    """æå–æ ‡ç­¾"""
    tags = []
    keywords = {
        'å¿µä½›': ['å¿µä½›', 'æŒå', 'å‡€åœŸ'],
        'ç¦…ä¿®': ['ç¦…', 'å‚ç¦…', 'æ‰“å', 'ç¦…å®š'],
        'èˆ¬è‹¥': ['èˆ¬è‹¥', 'æ™ºæ…§', 'ç©ºæ€§'],
        'æˆ’å¾‹': ['æˆ’', 'æŒæˆ’', 'å¾‹'],
        'è©æå¿ƒ': ['è©æå¿ƒ', 'å‘å¿ƒ', 'æ„¿'],
        'ç»å…¸': ['ç»', 'è®º', 'ç–']
    }
    
    text = f"{title} {summary} {' '.join(sections)}"
    
    for tag, words in keywords.items():
        if any(word in text for word in words):
            tags.append(tag)
    
    return tags[:5]

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ç”Ÿæˆç»“æ„åŒ–æ–‡ç« ...\n")
    
    # æºç›®å½•å’Œç›®æ ‡ç›®å½•
    source_dir = Path('rushuofoxueyuan/My Web Sites/xiuxueyd')
    articles_dir = Path('webapp/articles')
    
    if not source_dir.exists():
        print(f"âŒ æºç›®å½•ä¸å­˜åœ¨: {source_dir}")
        return
    
    # åˆ›å»ºæ–‡ç« ç›®å½•
    articles_dir.mkdir(exist_ok=True)
    
    # è·å–æ‰€æœ‰HTMLæ–‡ä»¶
    html_files = sorted(source_dir.glob('*.html'))
    
    print(f"ğŸ“š æ‰¾åˆ° {len(html_files)} ä¸ªHTMLæ–‡ä»¶")
    print("=" * 60)
    
    articles_index = []
    success_count = 0
    
    for i, file_path in enumerate(html_files, 1):
        filename = file_path.name
        
        # è·³è¿‡ç´¢å¼•é¡µ
        if filename in ['index.htm', 'index.html', 'frame.html']:
            continue
        
        print(f"[{i}/{len(html_files)}] è§£æ: {filename}")
        
        # è§£ææ–‡ä»¶
        parsed = parse_and_generate(file_path)
        
        if not parsed or not parsed['title']:
            print(f"  âš ï¸  è·³è¿‡(æ— æ ‡é¢˜)")
            continue
        
        # æå–ID
        file_id = re.match(r'(\d+)', filename)
        article_id = file_id.group(1) if file_id else filename.replace('.html', '')
        
        # æ„å»ºå®Œæ•´æ–‡ç« æ•°æ®
        article_data = {
            'id': article_id,
            'title': parsed['title'],
            'category': determine_category(filename),
            'tags': extract_tags(parsed['title'], parsed['summary'], parsed['sections']),
            'author': parsed['author'],
            'summary': parsed['summary'],
            'sections': parsed['sections'],
            'content': parsed['content']
        }
        
        # ä¿å­˜æ–‡ç« JSONæ–‡ä»¶
        article_file = articles_dir / f"{article_id}.json"
        with open(article_file, 'w', encoding='utf-8') as f:
            json.dump(article_data, f, ensure_ascii=False, indent=2)
        
        # ç´¢å¼•ä¸­åªä¿ç•™å…ƒæ•°æ®
        articles_index.append({
            'id': article_data['id'],
            'title': article_data['title'],
            'category': article_data['category'],
            'tags': article_data['tags'],
            'author': article_data['author'],
            'summary': article_data['summary'],
            'sections': article_data['sections']
        })
        
        success_count += 1
        print(f"  âœ“ {article_data['title']}")
        if article_data['sections']:
            print(f"    ç« èŠ‚: {', '.join(article_data['sections'][:3])}...")
    
    print("=" * 60)
    print(f"âœ… æˆåŠŸç”Ÿæˆ {success_count} ç¯‡æ–‡ç« ")
    
    # ä¿å­˜ç´¢å¼•
    index_file = 'webapp/articles-index.json'
    with open(index_file, 'w', encoding='utf-8') as f:
        json.dump(articles_index, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ ç´¢å¼•å·²ä¿å­˜åˆ°: {index_file}")
    print(f"ğŸ’¾ æ–‡ç« å·²ä¿å­˜åˆ°: {articles_dir}/")
    
    # ç»Ÿè®¡
    print("\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"  æ€»æ–‡ç« æ•°: {success_count}")
    
    categories = {}
    for article in articles_index:
        cat = article['category']
        categories[cat] = categories.get(cat, 0) + 1
    
    for cat, count in categories.items():
        print(f"  {cat}: {count} ç¯‡")
    
    # æ–‡ä»¶å¤§å°
    index_size = os.path.getsize(index_file) / 1024
    total_size = sum(f.stat().st_size for f in articles_dir.glob('*.json')) / 1024
    
    print(f"\nğŸ“¦ ç´¢å¼•æ–‡ä»¶: {index_size:.2f} KB")
    print(f"ğŸ“¦ æ–‡ç« æ–‡ä»¶æ€»è®¡: {total_size:.2f} KB")
    
    print("\nâœ¨ å®Œæˆ!")

if __name__ == '__main__':
    main()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”Ÿæˆæ–‡ç« ç´¢å¼• - ä»åŸå§‹HTMLæ–‡ä»¶æå–å…ƒæ•°æ®å¹¶ç”Ÿæˆæ–°çš„æ–‡ç« æ–‡ä»¶
"""

import os
import json
import re
from html.parser import HTMLParser
from pathlib import Path

class ArticleParser(HTMLParser):
    """è§£æHTMLæ–‡ç« ,æå–å…ƒæ•°æ®å’Œå†…å®¹"""
    
    def __init__(self):
        super().__init__()
        self.title = ""
        self.author = ""
        self.summary = ""
        self.sections = []
        self.content_parts = []
        self.current_tag = ""
        self.current_attrs = {}
        self.in_title = False
        self.in_author = False
        self.in_summary = False
        self.in_section = False
        self.in_content = False
        self.summary_count = 0
        self.skip_nav = 0
        
    def handle_starttag(self, tag, attrs):
        self.current_tag = tag
        self.current_attrs = dict(attrs)
        
        # æ£€æµ‹ä¸»å†…å®¹è¡¨æ ¼
        if tag == 'table' and self.current_attrs.get('bgcolor') == '#FFFFFF':
            self.in_content = True
            return
        
        if not self.in_content:
            return
            
        # æ£€æµ‹æ ‡é¢˜ (H2æ ‡ç­¾)
        if tag == 'h2':
            self.in_title = True
            
        # æ£€æµ‹ç« èŠ‚æ ‡é¢˜ (H4æ ‡ç­¾)
        if tag == 'h4':
            self.in_section = True
            self.content_parts.append(('section', ''))
            
        # æ£€æµ‹æ‘˜è¦ (çº¢è‰²æ¥·ä½“çš„æ®µè½)
        if tag == 'p' or tag == 'font':
            style = self.current_attrs.get('style', '')
            color = self.current_attrs.get('color', '')
            face = self.current_attrs.get('face', '')
            align = self.current_attrs.get('align', '')
            
            # è·³è¿‡å¯¼èˆª
            if align == 'CENTER' and self.skip_nav < 3:
                self.skip_nav += 1
                return
            
            # çº¢è‰²æ¥·ä½“é€šå¸¸æ˜¯æ‘˜è¦
            if ('CC3300' in color or 'FF0000' in color) and ('æ¥·ä½“' in face or 'æ¥·ä½“' in style):
                if self.summary_count < 3:
                    self.in_summary = True
                    self.content_parts.append(('summary', ''))
    
    def handle_endtag(self, tag):
        if tag == 'table' and self.in_content:
            self.in_content = False
            
        if tag == 'h2':
            self.in_title = False
        if tag == 'h4':
            self.in_section = False
        if tag == 'p' or tag == 'font':
            if self.in_summary:
                self.in_summary = False
                self.summary_count += 1
    
    def handle_data(self, data):
        data = data.strip()
        if not data:
            return
            
        # æå–æ ‡é¢˜
        if self.in_title and not self.title:
            clean_title = re.sub(r'["\']', '', data)
            clean_title = re.sub(r'-å¦‚è¯´ä¿®è¡Œ.*', '', clean_title)
            self.title = clean_title.strip()
        
        # æå–ç« èŠ‚
        if self.in_section:
            clean_section = re.sub(r'^\d+[ã€.]', '', data)
            clean_section = clean_section.strip()
            if clean_section and clean_section not in self.sections:
                self.sections.append(clean_section)
                if self.content_parts and self.content_parts[-1][0] == 'section':
                    self.content_parts[-1] = ('section', clean_section)
        
        # æå–æ‘˜è¦
        if self.in_summary and self.summary_count < 3:
            clean_summary = re.sub(r'["\']', '', data)
            clean_summary = clean_summary.strip()
            if clean_summary and len(clean_summary) > 10:
                if self.summary:
                    self.summary += " " + clean_summary
                else:
                    self.summary = clean_summary
                    
                if self.content_parts and self.content_parts[-1][0] == 'summary':
                    self.content_parts[-1] = ('summary', clean_summary)
        
        # æ”¶é›†æ­£æ–‡å†…å®¹
        if self.in_content and not self.in_title and not self.skip_nav:
            if data and len(data) > 5:
                self.content_parts.append(('text', data))

def parse_html_file(file_path):
    """è§£æå•ä¸ªHTMLæ–‡ä»¶"""
    try:
        encodings = ['gb2312', 'gbk', 'utf-8', 'gb18030']
        content = None
        
        for encoding in encodings:
            try:
                with open(file_path, 'r', encoding=encoding) as f:
                    content = f.read()
                break
            except UnicodeDecodeError:
                continue
        
        if not content:
            print(f"âš ï¸  æ— æ³•è¯»å–æ–‡ä»¶: {file_path}")
            return None
        
        parser = ArticleParser()
        parser.feed(content)
        
        return {
            'title': parser.title,
            'author': parser.author,
            'summary': parser.summary[:200] if parser.summary else "",
            'sections': parser.sections,
            'content_parts': parser.content_parts
        }
        
    except Exception as e:
        print(f"âŒ è§£æå¤±è´¥ {file_path}: {e}")
        return None

def generate_article_html(metadata, article_id):
    """ç”Ÿæˆæ–°çš„æ–‡ç« HTMLæ–‡ä»¶"""
    
    html = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{metadata['title']} - å¦‚è¯´ä¿®è¡Œç½‘ä¸Šä½›å­¦é™¢</title>
</head>
<body>
    <article>
        <h1>{metadata['title']}</h1>
"""
    
    if metadata['summary']:
        html += f"""        <div class="summary">{metadata['summary']}</div>\n"""
    
    if metadata['sections']:
        html += """        <nav class="toc">\n            <h2>ç›®å½•</h2>\n            <ul>\n"""
        for i, section in enumerate(metadata['sections']):
            html += f"""                <li><a href="#section-{i}">{section}</a></li>\n"""
        html += """            </ul>\n        </nav>\n"""
    
    html += """        <div class="content">\n"""
    
    section_index = 0
    for part_type, part_content in metadata['content_parts']:
        if part_type == 'section':
            html += f"""            <h2 id="section-{section_index}">{part_content}</h2>\n"""
            section_index += 1
        elif part_type == 'summary':
            html += f"""            <p class="highlight">{part_content}</p>\n"""
        elif part_type == 'text':
            html += f"""            <p>{part_content}</p>\n"""
    
    html += """        </div>
    </article>
</body>
</html>
"""
    
    return html

def determine_category(filename):
    """æ ¹æ®æ–‡ä»¶åæˆ–è·¯å¾„åˆ¤æ–­åˆ†ç±»"""
    if 'chan' in filename or 'ç¦…' in filename:
        return 'ç¦…ä¿®é™¢'
    elif 'jingtu' in filename or 'å‡€åœŸ' in filename:
        return 'å‡€ä¿®é™¢'
    else:
        return 'ä¿®å­¦å›­åœ°'

def extract_tags(title, summary, sections):
    """ä»æ ‡é¢˜ã€æ‘˜è¦ã€ç« èŠ‚ä¸­æå–æ ‡ç­¾"""
    tags = []
    
    keywords = {
        'å¿µä½›': ['å¿µä½›', 'æŒå', 'å‡€åœŸ'],
        'ç¦…ä¿®': ['ç¦…', 'å‚ç¦…', 'æ‰“å', 'ç¦…å®š'],
        'èˆ¬è‹¥': ['èˆ¬è‹¥', 'æ™ºæ…§', 'ç©ºæ€§'],
        'æˆ’å¾‹': ['æˆ’', 'æŒæˆ’', 'å¾‹'],
        'å› æœ': ['å› æœ', 'ä¸šåŠ›', 'è½®å›'],
        'è©æå¿ƒ': ['è©æå¿ƒ', 'å‘å¿ƒ', 'æ„¿'],
        'ç»å…¸': ['ç»', 'è®º', 'ç–']
    }
    
    text = f"{title} {summary} {' '.join(sections)}"
    
    for tag, words in keywords.items():
        if any(word in text for word in words):
            tags.append(tag)
    
    return tags[:5]

def generate_index():
    """ç”Ÿæˆæ–‡ç« ç´¢å¼•å¹¶åˆ›å»ºæ–°çš„æ–‡ç« æ–‡ä»¶"""
    
    source_dir = Path('rushuofoxueyuan/My Web Sites/xiuxueyd')
    output_dir = Path('webapp/articles')
    
    if not source_dir.exists():
        print(f"âŒ æºç›®å½•ä¸å­˜åœ¨: {source_dir}")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir.mkdir(parents=True, exist_ok=True)
    
    html_files = sorted(source_dir.glob('*.html'))
    
    print(f"ğŸ“š æ‰¾åˆ° {len(html_files)} ä¸ªHTMLæ–‡ä»¶")
    print("=" * 60)
    
    articles = []
    
    for i, file_path in enumerate(html_files, 1):
        filename = file_path.name
        
        if filename in ['index.htm', 'index.html', 'frame.html']:
            continue
        
        print(f"[{i}/{len(html_files)}] è§£æ: {filename}")
        
        metadata = parse_html_file(file_path)
        
        if not metadata or not metadata['title']:
            print(f"  âš ï¸  è·³è¿‡(æ— æ ‡é¢˜)")
            continue
        
        file_id = re.match(r'(\d+)', filename)
        article_id = file_id.group(1) if file_id else filename.replace('.html', '')
        
        # ç”Ÿæˆæ–°çš„æ–‡ç« HTML
        new_html = generate_article_html(metadata, article_id)
        new_file = output_dir / f"{article_id}.html"
        
        with open(new_file, 'w', encoding='utf-8') as f:
            f.write(new_html)
        
        article = {
            'id': article_id,
            'title': metadata['title'],
            'file': f"articles/{article_id}.html",
            'category': determine_category(filename),
            'tags': extract_tags(metadata['title'], metadata['summary'], metadata['sections']),
            'author': metadata['author'] or '',
            'summary': metadata['summary'],
            'sections': metadata['sections']
        }
        
        articles.append(article)
        
        print(f"  âœ“ {article['title']}")
        if article['sections']:
            print(f"    ç« èŠ‚: {', '.join(article['sections'][:3])}...")
    
    print("=" * 60)
    print(f"âœ… æˆåŠŸè§£æ {len(articles)} ç¯‡æ–‡ç« ")
    
    # ä¿å­˜ç´¢å¼•
    output_file = 'webapp/articles-index.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(articles, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ ç´¢å¼•å·²ä¿å­˜åˆ°: {output_file}")
    
    categories = {}
    for article in articles:
        cat = article['category']
        categories[cat] = categories.get(cat, 0) + 1
    
    print("\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"  æ€»æ–‡ç« æ•°: {len(articles)}")
    for cat, count in categories.items():
        print(f"  {cat}: {count} ç¯‡")
    
    size_kb = os.path.getsize(output_file) / 1024
    print(f"\nğŸ“¦ ç´¢å¼•æ–‡ä»¶å¤§å°: {size_kb:.2f} KB")
    
    return articles

if __name__ == '__main__':
    print("ğŸš€ å¼€å§‹ç”Ÿæˆæ–‡ç« ç´¢å¼•å’Œæ–°æ–‡ç« æ–‡ä»¶...\n")
    articles = generate_index()
    print("\nâœ¨ å®Œæˆ!")
